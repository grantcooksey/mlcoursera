{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Decision Trees\n",
    "This notebook is designed to make an initial exploration of decision trees.  It will use the week 3 loan dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loans = pd.read_csv(\"./lending-club-data.csv\", dtype={'next_pymnt_d':str, 'desc':str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Format the target column to reflect safe as 1 and a risky loan as -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loans['target'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "loans = loans.drop('bad_loans', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Split the data in train_raw and test_raw set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_raw, test_raw = train_test_split(loans, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Display the percentage of risky and safe loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safe: 81.16%\n",
      "Risky: 18.84%\n",
      "Size of training set: 98085\n"
     ]
    }
   ],
   "source": [
    "percent_safe_raw = train_raw[train_raw['target'] == 1].size / (1.0 * train_raw.size) * 100\n",
    "percent_risky_raw = train_raw[train_raw['target'] == -1].size / (1.0 * train_raw.size) * 100\n",
    "\n",
    "print('Safe: {0:.2f}%'.format(percent_safe_raw))\n",
    "print('Risky: {0:.2f}%'.format(percent_risky_raw))\n",
    "print('Size of training set: {0}'.format(len(train_raw.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Effect of Unbalanced data\n",
    "If there is a class inbalance, there is a chance that it will bias what the majority class will be.  This section explores this concept and shows class imbalance would affect feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Compute classification error for a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def classification_error(data, feat='', target='target', Verbose=False):\n",
    "    '''Calculates classification error\n",
    "    \n",
    "    Loops through each catagory in the feature and calculates the \n",
    "    classification error.  If the feature name is empty, the method\n",
    "    calculates the classification error of the local root.\n",
    "    \n",
    "    Args:\n",
    "        feat (str): Catagorical variable name or the empty string\n",
    "        target (str): associated data should be binary\n",
    "        \n",
    "    Returns\n",
    "        float: The classification error.\n",
    "    '''\n",
    "    if feat is '': # Root\n",
    "        num_pos = len(data[data[target] == 1].index)\n",
    "        num_neg = len(data[data[target] == -1].index)\n",
    "        if num_pos > num_neg:\n",
    "            return num_neg / float(len(data.index))\n",
    "        else:\n",
    "            return num_pos / float(len(data.index))\n",
    "    else: # Not the root\n",
    "        num_error = 0\n",
    "\n",
    "        bins = data[feat].unique()\n",
    "        for value in bins.tolist():\n",
    "            data_in_bin = data[data[feat] == value]\n",
    "            num_pos = len(data_in_bin[data_in_bin[target] == 1].index)\n",
    "            num_neg = len(data_in_bin[data_in_bin[target] == -1].index)\n",
    "            if Verbose:\n",
    "                print('In feature', value)\n",
    "                print('Safe: {0:.2f}% with {1} total'.format(num_pos/ float(len(data_in_bin.index)) * 100, num_pos))\n",
    "                print('Risky: {0:.2f}% with {1} total'.format(num_neg / float(len(data_in_bin.index)) * 100, num_neg))\n",
    "                print('-------------------')\n",
    "            if num_pos > num_neg:\n",
    "                num_error += num_neg\n",
    "            else:\n",
    "                num_error += num_pos\n",
    "\n",
    "        return num_error / float(len(data.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For each feature, print the percentage of risky vs safe loans and the classification error for the feature.  Since there is a class imbalance, the classifiction error is the same as the root without any features added even though this is an unlikely senario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------grade----------\n",
      "('In feature', 'B')\n",
      "Safe: 85.38% with 25383 total\n",
      "Risky: 14.62% with 4346 total\n",
      "-------------------\n",
      "('In feature', 'C')\n",
      "Safe: 79.45% with 19069 total\n",
      "Risky: 20.55% with 4933 total\n",
      "-------------------\n",
      "('In feature', 'A')\n",
      "Safe: 92.98% with 16631 total\n",
      "Risky: 7.02% with 1255 total\n",
      "-------------------\n",
      "('In feature', 'D')\n",
      "Safe: 73.20% with 11193 total\n",
      "Risky: 26.80% with 4098 total\n",
      "-------------------\n",
      "('In feature', 'E')\n",
      "Safe: 68.20% with 4916 total\n",
      "Risky: 31.80% with 2292 total\n",
      "-------------------\n",
      "('In feature', 'F')\n",
      "Safe: 60.98% with 1896 total\n",
      "Risky: 39.02% with 1213 total\n",
      "-------------------\n",
      "('In feature', 'G')\n",
      "Safe: 60.00% with 516 total\n",
      "Risky: 40.00% with 344 total\n",
      "-------------------\n",
      "0.188418208697\n",
      "--------term----------\n",
      "('In feature', ' 36 months')\n",
      "Safe: 84.01% with 65733 total\n",
      "Risky: 15.99% with 12510 total\n",
      "-------------------\n",
      "('In feature', ' 60 months')\n",
      "Safe: 69.91% with 13871 total\n",
      "Risky: 30.09% with 5971 total\n",
      "-------------------\n",
      "0.188418208697\n",
      "--------home_ownership----------\n",
      "('In feature', 'RENT')\n",
      "Safe: 79.07% with 33728 total\n",
      "Risky: 20.93% with 8928 total\n",
      "-------------------\n",
      "('In feature', 'OWN')\n",
      "Safe: 80.56% with 6354 total\n",
      "Risky: 19.44% with 1533 total\n",
      "-------------------\n",
      "('In feature', 'MORTGAGE')\n",
      "Safe: 83.15% with 39412 total\n",
      "Risky: 16.85% with 7988 total\n",
      "-------------------\n",
      "('In feature', 'OTHER')\n",
      "Safe: 77.46% with 110 total\n",
      "Risky: 22.54% with 32 total\n",
      "-------------------\n",
      "0.188418208697\n",
      "--------emp_length----------\n",
      "('In feature', 'n/a')\n",
      "Safe: 73.42% with 2378 total\n",
      "Risky: 26.58% with 861 total\n",
      "-------------------\n",
      "('In feature', '6 years')\n",
      "Safe: 79.94% with 4891 total\n",
      "Risky: 20.06% with 1227 total\n",
      "-------------------\n",
      "('In feature', '3 years')\n",
      "Safe: 81.99% with 6768 total\n",
      "Risky: 18.01% with 1487 total\n",
      "-------------------\n",
      "('In feature', '4 years')\n",
      "Safe: 81.61% with 5573 total\n",
      "Risky: 18.39% with 1256 total\n",
      "-------------------\n",
      "('In feature', '10+ years')\n",
      "Safe: 81.52% with 22251 total\n",
      "Risky: 18.48% with 5045 total\n",
      "-------------------\n",
      "('In feature', '5 years')\n",
      "Safe: 81.40% with 6246 total\n",
      "Risky: 18.60% with 1427 total\n",
      "-------------------\n",
      "('In feature', '2 years')\n",
      "Safe: 82.75% with 7956 total\n",
      "Risky: 17.25% with 1658 total\n",
      "-------------------\n",
      "('In feature', '1 year')\n",
      "Safe: 81.52% with 5732 total\n",
      "Risky: 18.48% with 1299 total\n",
      "-------------------\n",
      "('In feature', '< 1 year')\n",
      "Safe: 81.47% with 7217 total\n",
      "Risky: 18.53% with 1642 total\n",
      "-------------------\n",
      "('In feature', '8 years')\n",
      "Safe: 81.22% with 3455 total\n",
      "Risky: 18.78% with 799 total\n",
      "-------------------\n",
      "('In feature', '9 years')\n",
      "Safe: 80.46% with 2845 total\n",
      "Risky: 19.54% with 691 total\n",
      "-------------------\n",
      "('In feature', '7 years')\n",
      "Safe: 79.76% with 4292 total\n",
      "Risky: 20.24% with 1089 total\n",
      "-------------------\n",
      "0.188418208697\n"
     ]
    }
   ],
   "source": [
    "features = ['grade',              # grade of the loan\n",
    "            'term',               # the term of the loan\n",
    "            'home_ownership',     # home_ownership status: own, mortgage or rent\n",
    "            'emp_length',         # number of years of employment\n",
    "           ]\n",
    "for feature in features:\n",
    "    print('--------{0}----------'.format(feature))\n",
    "    print(classification_error(train_raw, feature, 'target', Verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We will use a simple method to balance the class.  We will remove rows from the majority class till the classes are balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 76.78% of the safe set\n",
      "Removed 61123 items\n",
      "Safe: 50.00%\n",
      "Risky: 50.00%\n",
      "Size of new training set: 36962\n"
     ]
    }
   ],
   "source": [
    "percentage_to_remove = 1 - (percent_risky_raw / percent_safe_raw)\n",
    "train_raw_safe = train_raw[train_raw['target'] == 1]\n",
    "\n",
    "print(\"Removing {0:.2f}% of the safe set\".format(percentage_to_remove*100))\n",
    "\n",
    "# Ignore the returned test split\n",
    "train_safe,_ = train_test_split(train_raw_safe, test_size=percentage_to_remove, random_state=1)\n",
    "\n",
    "# Combine reduced safe set with raw risky set\n",
    "train = pd.concat([train_safe, train_raw[train_raw['target'] == -1]])\n",
    "\n",
    "percent_safe = train[train['target'] == 1].size / (1.0 * train.size) * 100\n",
    "percent_risky = train[train['target'] == -1].size / (1.0 * train.size) * 100\n",
    "\n",
    "print(\"Removed {0} items\".format(len(train_raw.index)-len(train.index)))\n",
    "print('Safe: {0:.2f}%'.format(percent_safe))\n",
    "print('Risky: {0:.2f}%'.format(percent_risky))\n",
    "print('Size of new training set: {0}'.format(len(train.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now if we run for classification error again we get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------grade----------\n",
      "0.386829717007\n",
      "--------term----------\n",
      "0.423597207943\n",
      "--------home_ownership----------\n",
      "0.47251230994\n",
      "--------emp_length----------\n",
      "0.485552729831\n"
     ]
    }
   ],
   "source": [
    "for feature in features:\n",
    "    print('--------{0}----------'.format(feature))\n",
    "    print(classification_error(train, feature, 'target'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Building the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def majority_class(data, target):\n",
    "    num_pos = len(data[data[target] == 1].index)\n",
    "    num_neg = len(data[data[target] == -1].index)\n",
    "    if num_pos > num_neg:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def next_feature(data, features, target):\n",
    "    '''Performs a single step of feature seletion.\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame)\n",
    "        features (array_like): list of features referencing columns in the data\n",
    "        target (str): name of target column in the data\n",
    "    \n",
    "    Note:\n",
    "        Data target must be a binary catagory where positive is 1 and\n",
    "        negative is -1.\n",
    "        \n",
    "    Todo:\n",
    "        Add support for non binary classification.\n",
    "        \n",
    "    Returns:\n",
    "        str: The name of feature with the lowest classification error\n",
    "            or None if the root has the lowest classification error.\n",
    "    '''\n",
    "    error = pd.DataFrame([[classification_error(data), 'root']], columns=['error', 'feat'])\n",
    "\n",
    "    for f in features:\n",
    "        error = error.append(pd.DataFrame([[classification_error(data, f, target), f]]\n",
    "                                         , columns=['error', 'feat']),\n",
    "                            ignore_index=True)\n",
    "    \n",
    "    lowest_error = error.loc[error['error'].idxmin(0)]\n",
    "    \n",
    "    if lowest_error['feat'] is 'root':\n",
    "        return None\n",
    "    else:\n",
    "        return lowest_error['feat']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To ease this process, we define a class to represent a node in the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    def __init__(self, feature=None, branches=None, is_leaf=False, result=None):\n",
    "        self.is_leaf = is_leaf\n",
    "        self.result = result\n",
    "        self.feature = feature\n",
    "        self.branches = branches\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '(Tree - leaf: {0} - result: {1} - feature: {2})'.format(self.is_leaf,\n",
    "                                                        self.result, self. feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_tree(data, features, target, depth, last_feature=None):\n",
    "    '''Recursively builds binary decision tree\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame): Sample and feature data.\n",
    "        features (array_like): List of names of features that map to\n",
    "            columns in the data.\n",
    "        target (str): Name of target column in data.\n",
    "        depth (int): Maximum depth of tree.\n",
    "        \n",
    "    Note:\n",
    "        Target data is assumes to be of the form 1 or -1. This method\n",
    "        buuilds a binary decision tree not a binary tree.\n",
    "        \n",
    "    Returns:\n",
    "        Tree: The root node of the binary decision tree.\n",
    "    '''\n",
    "    current_feature = next_feature(data, features, target)\n",
    "\n",
    "    #print('last: {0} --- current: {1} -- Same: {2}'.format(\n",
    "    #    last_feature, current_feature, last_feature == current_feature))\n",
    "    \n",
    "    # Leaf node\n",
    "    if depth == 0 or current_feature is None or current_feature == last_feature:\n",
    "        #print('Leaf ----->>> last: {0} --- current: {1} -- Same: {2}'.format(\n",
    "        #    last_feature, current_feature, last_feature == current_feature))\n",
    "        return Tree(is_leaf=True, result=majority_class(data, target))\n",
    "    \n",
    "    depth -= 1\n",
    "    bins = data[current_feature].unique()\n",
    "    node = Tree(feature=current_feature, branches={})\n",
    "    for val in bins:\n",
    "        node.branches[val] = build_tree(data[data[current_feature] == val], \n",
    "                                        features, target, depth,\n",
    "                                        last_feature=current_feature)\n",
    "    \n",
    "    return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we will build a model using the 4 features we previously defined and a depth of 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_model = build_tree(train, features, 'target', 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting a loan application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def traverse(data, node):\n",
    "    if node.is_leaf:\n",
    "        return node.result\n",
    "    next_node = node.branches[data[node.feature]]\n",
    "    return traverse(data, next_node)\n",
    "\n",
    "def predict(model, data):\n",
    "    '''Predicts whether a binary classifaction using decision tree\n",
    "    \n",
    "    Args:\n",
    "        model (Tree): Decision tree.\n",
    "        data (Dataframe): Items to predict.\n",
    "    \n",
    "    Returns:\n",
    "        ndarray: Predictions of either 1 or -1. \n",
    "    '''\n",
    "    return data.apply(lambda x: traverse(x, model), axis=1).as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we extract the true results from the training set and use the model to make equivalent predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_output = train['target'].as_matrix()\n",
    "train_predictions = predict(simple_model, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, recall that the **classification error** is defined as follows:\n",
    "$$\n",
    "\\mbox{classification error} = \\frac{\\mbox{# mistakes}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "First calcuate classification error on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification error: 37.56%\n"
     ]
    }
   ],
   "source": [
    "train_num_error = len(train_output) - np.count_nonzero(train_output + train_predictions)\n",
    "print('Classification error: {0:.2f}%'.format(train_num_error/float(len(train_output))* 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate the classification error of the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('OTHER', u'occurred at index 80284')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-8dd1d797b2d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_num_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Classification error: {0:.2f}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_num_error\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-94585702ebbd>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPredictions\u001b[0m \u001b[0mof\u001b[0m \u001b[0meither\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     '''\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/grant/ml/ml-env/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   4150\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4151\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4152\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4154\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/grant/ml/ml-env/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4246\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4247\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4248\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4249\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4250\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-94585702ebbd>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPredictions\u001b[0m \u001b[0mof\u001b[0m \u001b[0meither\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     '''\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-65-94585702ebbd>\u001b[0m in \u001b[0;36mtraverse\u001b[0;34m(data, node)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnext_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbranches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-94585702ebbd>\u001b[0m in \u001b[0;36mtraverse\u001b[0;34m(data, node)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnext_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbranches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-94585702ebbd>\u001b[0m in \u001b[0;36mtraverse\u001b[0;34m(data, node)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnext_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbranches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-94585702ebbd>\u001b[0m in \u001b[0;36mtraverse\u001b[0;34m(data, node)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mnext_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbranches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('OTHER', u'occurred at index 80284')"
     ]
    }
   ],
   "source": [
    "test_output = test_raw['target'].as_matrix()\n",
    "test_predictions = predict(simple_model, test_raw)\n",
    "\n",
    "test_num_error = len(test_output) - np.count_nonzero(test_output + test_predictions)\n",
    "print('Classification error: {0:.2f}%'.format(test_num_error/float(len(test_output))* 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
