{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Decision Trees\n",
    "This notebook is designed to make an initial exploration of decision trees.  It will use the week 3 loan dataset.\n",
    "\n",
    "Data is from week 3 coursera course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loans = pd.read_csv(\"./lending-club-data.csv\", dtype={'next_pymnt_d':str, 'desc':str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Format the target column to reflect safe as 1 and a risky loan as -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loans['target'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "loans = loans.drop('bad_loans', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Split the data in train_raw and test_raw set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_raw, test_raw = train_test_split(loans, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Display the percentage of risky and safe loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safe: 81.16%\n",
      "Risky: 18.84%\n",
      "Size of training set: 98085\n"
     ]
    }
   ],
   "source": [
    "percent_safe_raw = train_raw[train_raw['target'] == 1].size / (1.0 * train_raw.size) * 100\n",
    "percent_risky_raw = train_raw[train_raw['target'] == -1].size / (1.0 * train_raw.size) * 100\n",
    "\n",
    "print('Safe: {0:.2f}%'.format(percent_safe_raw))\n",
    "print('Risky: {0:.2f}%'.format(percent_risky_raw))\n",
    "print('Size of training set: {0}'.format(len(train_raw.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Effect of Unbalanced data\n",
    "If there is a class inbalance, there is a chance that it will bias what the majority class will be.  This section explores this concept and shows class imbalance would affect feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Compute classification error for a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def classification_error(data, feat='', target='target', Verbose=False):\n",
    "    '''Calculates classification error\n",
    "    \n",
    "    Loops through each catagory in the feature and calculates the \n",
    "    classification error.  If the feature name is empty, the method\n",
    "    calculates the classification error of the local root.\n",
    "    \n",
    "    Args:\n",
    "        feat (str): Catagorical variable name or the empty string\n",
    "        target (str): associated data should be binary\n",
    "        \n",
    "    Returns\n",
    "        float: The classification error.\n",
    "    '''\n",
    "    if feat is '': # Root\n",
    "        num_pos = len(data[data[target] == 1].index)\n",
    "        num_neg = len(data[data[target] == -1].index)\n",
    "        if num_pos > num_neg:\n",
    "            return num_neg / float(len(data.index))\n",
    "        else:\n",
    "            return num_pos / float(len(data.index))\n",
    "    else: # Not the root\n",
    "        num_error = 0\n",
    "\n",
    "        bins = data[feat].unique()\n",
    "        for value in bins.tolist():\n",
    "            data_in_bin = data[data[feat] == value]\n",
    "            num_pos = len(data_in_bin[data_in_bin[target] == 1].index)\n",
    "            num_neg = len(data_in_bin[data_in_bin[target] == -1].index)\n",
    "            if Verbose:\n",
    "                print('In feature', value)\n",
    "                print('Safe: {0:.2f}% with {1} total'.format(num_pos/ float(len(data_in_bin.index)) * 100, num_pos))\n",
    "                print('Risky: {0:.2f}% with {1} total'.format(num_neg / float(len(data_in_bin.index)) * 100, num_neg))\n",
    "                print('-------------------')\n",
    "            if num_pos > num_neg:\n",
    "                num_error += num_neg\n",
    "            else:\n",
    "                num_error += num_pos\n",
    "\n",
    "        return num_error / float(len(data.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For each feature, print the percentage of risky vs safe loans and the classification error for the feature.  Since there is a class imbalance, the classifiction error is the same as the root without any features added even though this is an unlikely senario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------grade----------\n",
      "('In feature', 'B')\n",
      "Safe: 85.38% with 25383 total\n",
      "Risky: 14.62% with 4346 total\n",
      "-------------------\n",
      "('In feature', 'C')\n",
      "Safe: 79.45% with 19069 total\n",
      "Risky: 20.55% with 4933 total\n",
      "-------------------\n",
      "('In feature', 'A')\n",
      "Safe: 92.98% with 16631 total\n",
      "Risky: 7.02% with 1255 total\n",
      "-------------------\n",
      "('In feature', 'D')\n",
      "Safe: 73.20% with 11193 total\n",
      "Risky: 26.80% with 4098 total\n",
      "-------------------\n",
      "('In feature', 'E')\n",
      "Safe: 68.20% with 4916 total\n",
      "Risky: 31.80% with 2292 total\n",
      "-------------------\n",
      "('In feature', 'F')\n",
      "Safe: 60.98% with 1896 total\n",
      "Risky: 39.02% with 1213 total\n",
      "-------------------\n",
      "('In feature', 'G')\n",
      "Safe: 60.00% with 516 total\n",
      "Risky: 40.00% with 344 total\n",
      "-------------------\n",
      "0.188418208697\n",
      "--------term----------\n",
      "('In feature', ' 36 months')\n",
      "Safe: 84.01% with 65733 total\n",
      "Risky: 15.99% with 12510 total\n",
      "-------------------\n",
      "('In feature', ' 60 months')\n",
      "Safe: 69.91% with 13871 total\n",
      "Risky: 30.09% with 5971 total\n",
      "-------------------\n",
      "0.188418208697\n",
      "--------home_ownership----------\n",
      "('In feature', 'RENT')\n",
      "Safe: 79.07% with 33728 total\n",
      "Risky: 20.93% with 8928 total\n",
      "-------------------\n",
      "('In feature', 'OWN')\n",
      "Safe: 80.56% with 6354 total\n",
      "Risky: 19.44% with 1533 total\n",
      "-------------------\n",
      "('In feature', 'MORTGAGE')\n",
      "Safe: 83.15% with 39412 total\n",
      "Risky: 16.85% with 7988 total\n",
      "-------------------\n",
      "('In feature', 'OTHER')\n",
      "Safe: 77.46% with 110 total\n",
      "Risky: 22.54% with 32 total\n",
      "-------------------\n",
      "0.188418208697\n",
      "--------emp_length----------\n",
      "('In feature', 'n/a')\n",
      "Safe: 73.42% with 2378 total\n",
      "Risky: 26.58% with 861 total\n",
      "-------------------\n",
      "('In feature', '6 years')\n",
      "Safe: 79.94% with 4891 total\n",
      "Risky: 20.06% with 1227 total\n",
      "-------------------\n",
      "('In feature', '3 years')\n",
      "Safe: 81.99% with 6768 total\n",
      "Risky: 18.01% with 1487 total\n",
      "-------------------\n",
      "('In feature', '4 years')\n",
      "Safe: 81.61% with 5573 total\n",
      "Risky: 18.39% with 1256 total\n",
      "-------------------\n",
      "('In feature', '10+ years')\n",
      "Safe: 81.52% with 22251 total\n",
      "Risky: 18.48% with 5045 total\n",
      "-------------------\n",
      "('In feature', '5 years')\n",
      "Safe: 81.40% with 6246 total\n",
      "Risky: 18.60% with 1427 total\n",
      "-------------------\n",
      "('In feature', '2 years')\n",
      "Safe: 82.75% with 7956 total\n",
      "Risky: 17.25% with 1658 total\n",
      "-------------------\n",
      "('In feature', '1 year')\n",
      "Safe: 81.52% with 5732 total\n",
      "Risky: 18.48% with 1299 total\n",
      "-------------------\n",
      "('In feature', '< 1 year')\n",
      "Safe: 81.47% with 7217 total\n",
      "Risky: 18.53% with 1642 total\n",
      "-------------------\n",
      "('In feature', '8 years')\n",
      "Safe: 81.22% with 3455 total\n",
      "Risky: 18.78% with 799 total\n",
      "-------------------\n",
      "('In feature', '9 years')\n",
      "Safe: 80.46% with 2845 total\n",
      "Risky: 19.54% with 691 total\n",
      "-------------------\n",
      "('In feature', '7 years')\n",
      "Safe: 79.76% with 4292 total\n",
      "Risky: 20.24% with 1089 total\n",
      "-------------------\n",
      "0.188418208697\n"
     ]
    }
   ],
   "source": [
    "features = ['grade',              # grade of the loan\n",
    "            'term',               # the term of the loan\n",
    "            'home_ownership',     # home_ownership status: own, mortgage or rent\n",
    "            'emp_length',         # number of years of employment\n",
    "           ]\n",
    "for feature in features:\n",
    "    print('--------{0}----------'.format(feature))\n",
    "    print(classification_error(train_raw, feature, 'target', Verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We will use a simple method to balance the class.  We will remove rows from the majority class till the classes are balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 76.78% of the safe set\n",
      "Removed 61123 items\n",
      "Safe: 50.00%\n",
      "Risky: 50.00%\n",
      "Size of new training set: 36962\n"
     ]
    }
   ],
   "source": [
    "percentage_to_remove = 1 - (percent_risky_raw / percent_safe_raw)\n",
    "train_raw_safe = train_raw[train_raw['target'] == 1]\n",
    "\n",
    "print(\"Removing {0:.2f}% of the safe set\".format(percentage_to_remove*100))\n",
    "\n",
    "# Ignore the returned test split\n",
    "train_safe,_ = train_test_split(train_raw_safe, test_size=percentage_to_remove, random_state=1)\n",
    "\n",
    "# Combine reduced safe set with raw risky set\n",
    "train = pd.concat([train_safe, train_raw[train_raw['target'] == -1]])\n",
    "\n",
    "percent_safe = train[train['target'] == 1].size / (1.0 * train.size) * 100\n",
    "percent_risky = train[train['target'] == -1].size / (1.0 * train.size) * 100\n",
    "\n",
    "print(\"Removed {0} items\".format(len(train_raw.index)-len(train.index)))\n",
    "print('Safe: {0:.2f}%'.format(percent_safe))\n",
    "print('Risky: {0:.2f}%'.format(percent_risky))\n",
    "print('Size of new training set: {0}'.format(len(train.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now if we run for classification error again we get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------grade----------\n",
      "0.386829717007\n",
      "--------term----------\n",
      "0.423597207943\n",
      "--------home_ownership----------\n",
      "0.47251230994\n",
      "--------emp_length----------\n",
      "0.485552729831\n"
     ]
    }
   ],
   "source": [
    "for feature in features:\n",
    "    print('--------{0}----------'.format(feature))\n",
    "    print(classification_error(train, feature, 'target'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Building the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def majority_class(data, target):\n",
    "    num_pos = len(data[data[target] == 1].index)\n",
    "    num_neg = len(data[data[target] == -1].index)\n",
    "    if num_pos > num_neg:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def next_feature(data, features, target):\n",
    "    '''Performs a single step of feature seletion.\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame)\n",
    "        features (array_like): list of features referencing columns in the data\n",
    "        target (str): name of target column in the data\n",
    "    \n",
    "    Note:\n",
    "        Data target must be a binary catagory where positive is 1 and\n",
    "        negative is -1.\n",
    "        \n",
    "    Todo:\n",
    "        Add support for non binary classification.\n",
    "        \n",
    "    Returns:\n",
    "        str: The name of feature with the lowest classification error\n",
    "            or None if the root has the lowest classification error.\n",
    "    '''\n",
    "    error = pd.DataFrame([[classification_error(data), 'root']], columns=['error', 'feat'])\n",
    "\n",
    "    for f in features:\n",
    "        error = error.append(pd.DataFrame([[classification_error(data, f, target), f]]\n",
    "                                         , columns=['error', 'feat']),\n",
    "                            ignore_index=True)\n",
    "    \n",
    "    lowest_error = error.loc[error['error'].idxmin(0)]\n",
    "    \n",
    "    if lowest_error['feat'] is 'root':\n",
    "        return None\n",
    "    else:\n",
    "        return lowest_error['feat']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To ease this process, we define a class to represent a node in the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    def __init__(self, feature=None, branches=None, strongest_feature_value=None, \n",
    "                 is_leaf=False, result=None):\n",
    "        self.is_leaf = is_leaf\n",
    "        self.result = result\n",
    "        self.feature = feature\n",
    "        self.branches = branches\n",
    "        self.strongest_feature_value = strongest_feature_value\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '(Tree - leaf: {0} - result: {1} - feature: {2})'.format(self.is_leaf,\n",
    "                                                        self.result, self. feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values\n",
    "When building the tree, as the tree depth increases, the data used to build the subtrees is reduced.  If the number of unique values for a feature is unbalanced this could be problematic because as the depth increases, so does that one of the values will be removed.  Thus, if a prediction has this value for the feature, there will be a `KeyError` if the item hits a node without the feature value.  To remedy this problem, each node with store the value of the feature with the lowest classification error and the the prediction will fall back to this value when traversing the tree.  \n",
    "\n",
    "**Note**: This method reduces the accuracy of the prediction but the tradeoff is that the model is more robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_tree(data, features, target, depth, last_feature=None):\n",
    "    '''Recursively builds binary decision tree\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame): Sample and feature data.\n",
    "        features (array_like): List of names of features that map to\n",
    "            columns in the data.\n",
    "        target (str): Name of target column in data.\n",
    "        depth (int): Maximum depth of tree.\n",
    "        \n",
    "    Note:\n",
    "        Target data is assumes to be of the form 1 or -1. This method\n",
    "        buuilds a binary decision tree not a binary tree.\n",
    "        \n",
    "    Returns:\n",
    "        Tree: The root node of the binary decision tree.\n",
    "    '''\n",
    "    current_feature = next_feature(data, features, target)\n",
    "\n",
    "    #print('last: {0} --- current: {1} -- Same: {2}'.format(\n",
    "    #    last_feature, current_feature, last_feature == current_feature))\n",
    "    \n",
    "    # Leaf node\n",
    "    if depth == 0 or current_feature is None or current_feature == last_feature:\n",
    "        #print('Leaf ----->>> last: {0} --- current: {1} -- Same: {2}'.format(\n",
    "        #    last_feature, current_feature, last_feature == current_feature))\n",
    "        return Tree(is_leaf=True, result=majority_class(data, target))\n",
    "    \n",
    "    depth -= 1\n",
    "    bins = data[current_feature].unique()\n",
    "    strongest_feature_value = data[current_feature].value_counts().index[0]\n",
    "    node = Tree(feature=current_feature, branches={}, \n",
    "                strongest_feature_value=strongest_feature_value)\n",
    "    for val in bins:\n",
    "        node.branches[val] = build_tree(data[data[current_feature] == val], \n",
    "                                        features, target, depth,\n",
    "                                        last_feature=current_feature)\n",
    "    \n",
    "    return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For simplicity, we will build a model using the 4 features we previously defined and a depth of 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "simple_model = build_tree(train, features, 'target', 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Predicting a loan application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def traverse(data, node):\n",
    "    if node.is_leaf:\n",
    "        return node.result\n",
    "    #print('Entering {0} : {1} : {2}'.format(node.feature, data[node.feature], [key for key,value in node.branches.iteritems()]))\n",
    "    if data[node.feature] in node.branches: \n",
    "        next_node = node.branches[data[node.feature]]\n",
    "    else: # Default to value with lowest classification error if value missing\n",
    "        next_node = node.branches[node.strongest_feature_value]\n",
    "    return traverse(data, next_node)\n",
    "\n",
    "def predict(model, data):\n",
    "    '''Predicts whether a binary classifaction using decision tree\n",
    "    \n",
    "    Args:\n",
    "        model (Tree): Decision tree.\n",
    "        data (Dataframe): Items to predict.\n",
    "    \n",
    "    Returns:\n",
    "        ndarray: Predictions of either 1 or -1. \n",
    "    '''\n",
    "    return data.apply(lambda x: traverse(x, model), axis=1).as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First we extract the true results from the training set and use the model to make equivalent predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_output = train['target'].as_matrix()\n",
    "train_predictions = predict(simple_model, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Again, recall that the **classification error** is defined as follows:\n",
    "$$\n",
    "\\mbox{classification error} = \\frac{\\mbox{# mistakes}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "First calcuate classification error on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification error: 37.56%\n"
     ]
    }
   ],
   "source": [
    "train_num_error = len(train_output) - np.count_nonzero(train_output + train_predictions)\n",
    "error_simple_train = train_num_error/float(len(train_output))* 100\n",
    "\n",
    "print('Classification error: {0:.2f}%'.format(error_simple_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now calculate the classification error of the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification error: 40.69%\n"
     ]
    }
   ],
   "source": [
    "test_output = test_raw['target'].as_matrix()\n",
    "test_predictions = predict(simple_model, test_raw)\n",
    "\n",
    "test_num_error = len(test_output) - np.count_nonzero(test_output + test_predictions)\n",
    "error_simple_test = test_num_error/float(len(test_output))* 100\n",
    "\n",
    "print('Classification error: {0:.2f}%'.format(error_simple_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding more features\n",
    "We will perform the same operations on the same data set but with a greater set of features to see what the effect is on classification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "large_features = ['grade',                     # grade of the loan\n",
    "            'short_emp',                 # one year or less of employment\n",
    "            'emp_length_num',            # number of years of employment\n",
    "            'home_ownership',            # home_ownership status: own, mortgage or rent\n",
    "            'purpose',                   # the purpose of the loan\n",
    "            'term',                      # the term of the loan\n",
    "            'last_delinq_none',          # has borrower had a delinquincy\n",
    "            'last_major_derog_none',     # has borrower had 90 day or worse rating\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grade: 7\n",
      "short_emp: 2\n",
      "emp_length_num: 12\n",
      "home_ownership: 4\n",
      "purpose: 12\n",
      "term: 2\n",
      "last_delinq_none: 2\n",
      "last_major_derog_none: 2\n"
     ]
    }
   ],
   "source": [
    "for f in large_features:\n",
    "    print('{0}: {1}'.format(f, len(train[f].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: This may take awhile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "large_model = build_tree(train, large_features, 'target', 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification error on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification error: 35.30%\n"
     ]
    }
   ],
   "source": [
    "train_predictions_large = predict(large_model, train)\n",
    "train_num_error_large = len(train_output) - np.count_nonzero(train_output + train_predictions_large)\n",
    "error_large_train = train_num_error_large/float(len(train_output))* 100\n",
    "\n",
    "print('Classification error: {0:.2f}%'.format(error_large_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification error on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification error: 42.91%\n"
     ]
    }
   ],
   "source": [
    "test_predictions_large = predict(large_model, test_raw)\n",
    "test_num_error_large = len(test_output) - np.count_nonzero(test_output + test_predictions_large)\n",
    "error_large_test = test_num_error_large/float(len(test_output))* 100\n",
    "\n",
    "print('Classification error: {0:.2f}%'.format(error_large_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the difference between the simple model and the complex model with the larger depth and feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between simple and complex training: 2.26\n",
      "Difference between simple and complex test: -2.22\n"
     ]
    }
   ],
   "source": [
    "print('Difference between simple and complex training: {0:.2f}'.format(\n",
    "    error_simple_train-error_large_train))\n",
    "print('Difference between simple and complex test: {0:.2f}'.format(\n",
    "    error_simple_test-error_large_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training error was reduced by using the complex model but test error increased.  This is an indication that overfitting may be present."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
